{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import sys\n","\n","drive.mount('/content/drive')\n","\n","base_dir = '/content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/'\n","!cd /content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/\n","\n","sys.path.append(base_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rJLBMqRCb5O","executionInfo":{"status":"ok","timestamp":1750082388326,"user_tz":-540,"elapsed":27358,"user":{"displayName":"김성연","userId":"09947970641122406209"}},"outputId":"45e27674-7b5f-4ef5-f0fc-b390a53f01cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"t6MPjfT5NrKQ"},"source":["# Jupyter notebook for debugging"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wbvMlHd_QwMG","executionInfo":{"status":"ok","timestamp":1750082455942,"user_tz":-540,"elapsed":2969,"user":{"displayName":"김성연","userId":"09947970641122406209"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3937db2c-ca40-4a9d-83da-cde0243a014a"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["%load_ext autoreload\n","%autoreload 2\n","\n","# Copied from `train` function in train_simple.py:L78\n","import yaml\n","\n","device = 'cpu'\n","hyp = base_dir + 'data/hyps/hyp.scratch-low.yaml'\n","\n","with open(hyp, errors=\"ignore\") as f:\n","    hyp = yaml.safe_load(f)  # load hyps dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JqYwIwtKBgjn","executionInfo":{"status":"ok","timestamp":1749799280657,"user_tz":-540,"elapsed":1454976,"user":{"displayName":"김성연","userId":"09947970641122406209"}},"outputId":"a2c61c59-2b6d-406c-8cc0-0c8ca6111850"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]},{"output_type":"stream","name":"stderr","text":["\n","Dataset not found ⚠️, missing paths ['/content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/datasets/nuscenes/val.txt']\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/VOCtest_06-Nov-2007.zip to /content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/datasets/nuscenes/images/VOCtest_06-Nov-2007.zip...\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/VOCtrainval_11-May-2012.zip to /content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/datasets/nuscenes/images/VOCtrainval_11-May-2012.zip...\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/VOCtrainval_06-Nov-2007.zip to /content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/datasets/nuscenes/images/VOCtrainval_06-Nov-2007.zip...\n","Unzipping /content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/datasets/nuscenes/images/VOCtest_06-Nov-2007.zip...\n","Unzipping /content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/datasets/nuscenes/images/VOCtrainval_06-Nov-2007.zip...\n","Unzipping /content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/datasets/nuscenes/images/VOCtrainval_11-May-2012.zip...\n","train2012: 100%|██████████| 5717/5717 [02:11<00:00, 43.32it/s]\n","val2012: 100%|██████████| 5823/5823 [02:19<00:00, 41.88it/s]\n","train2007: 100%|██████████| 2501/2501 [00:53<00:00, 46.95it/s]\n","val2007: 100%|██████████| 2510/2510 [00:36<00:00, 69.48it/s]\n","test2007: 100%|██████████| 4952/4952 [01:09<00:00, 71.16it/s]\n","Dataset download success ✅ (1343.4s), saved to \u001b[1m/content/drive/MyDrive/HYU/2025/AUE8088/project/datasets\u001b[0m\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100%|██████████| 755k/755k [00:00<00:00, 18.3MB/s]\n","Overriding model.yaml nc=4 with nc=15\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n","  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n","  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n","  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n","  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n","  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n"," 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n"," 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 24      [17, 20, 23]  1      9020  models.yolo.Detect                      [15, [[16, 30], [62, 45], [156, 198]], [64, 128, 256]]\n","YOLOv5n_nuscenes summary: 214 layers, 1766172 parameters, 1766172 gradients, 4.2 GFLOPs\n","\n"]}],"source":["from models.yolo import Model\n","from utils.general import check_dataset\n","\n","cfg = base_dir + 'models/yolov5n_nuscenes.yaml'\n","data = base_dir + 'data/nuscenes.yaml'\n","data_dict = check_dataset(data)\n","\n","nc = int(data_dict[\"nc\"])  # number of classes\n","model = Model(cfg, ch=3, nc=nc, anchors=hyp.get(\"anchors\")).to(device)  # create"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87HAYY9KBgjn"},"outputs":[],"source":["anchors = model.model[-1].anchors\n","\n","# [TODO] Draw anchors"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTo2nIP7Bgjn","executionInfo":{"status":"ok","timestamp":1749800601356,"user_tz":-540,"elapsed":43907,"user":{"displayName":"김성연","userId":"09947970641122406209"}},"outputId":"d33a83e2-b948-4230-d5d5-dc4c1afd4921"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n","size\n","  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n","    For further information visit https://errors.pydantic.dev/2.11/v/missing\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/datasets/nuscenes/labels/train2007... 2500 images, 1955 backgrounds, 0 corrupt: 100%|██████████| 2501/2501 [00:40<00:00, 61.62it/s] \n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/datasets/nuscenes/labels/train2007.cache\n"]}],"source":["from utils.dataloaders import create_dataloader\n","from utils.general import check_img_size, colorstr\n","\n","imgsz = 416\n","batch_size = 1\n","single_cls = False\n","seed = 0\n","\n","train_path = '/content/drive/MyDrive/HYU/2025/AUE8088/project/AUE8088/datasets/nuscenes/images/train2007' # data_dict[\"train\"]\n","gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n","imgsz = check_img_size(imgsz, gs, floor=gs * 2)  # verify imgsz is gs-multiple\n","\n","train_loader, dataset = create_dataloader(\n","    train_path,\n","    imgsz,\n","    batch_size,\n","    gs,\n","    single_cls,\n","    hyp=hyp,\n","    augment=True,\n","    cache=None,\n","    rect=False,\n","    rank=-1,\n","    workers=8,\n","    image_weights=False,\n","    quad=False,\n","    prefix=colorstr(\"train: \"),\n","    shuffle=True,\n","    seed=seed,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3h6oXj8Bgjn"},"outputs":[],"source":["for imgs, targets, paths, _, _ in train_loader:\n","    imgs = imgs.to(device, non_blocking=True).float() / 255  # uint8 to float32, 0-255 to 0.0-1.0\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bJYS3gz5Bgjo","executionInfo":{"status":"ok","timestamp":1749800801347,"user_tz":-540,"elapsed":1293,"user":{"displayName":"김성연","userId":"09947970641122406209"}},"outputId":"d8f02825-5068-4b81-e85e-6eaeeed5562e"},"outputs":[{"output_type":"stream","name":"stderr","text":["YOLOv5 🚀 2025-5-9 Python-3.11.13 torch-2.6.0+cu124 CPU\n","\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt to yolov5n.pt...\n","100%|██████████| 3.87M/3.87M [00:00<00:00, 96.3MB/s]\n","\n","Fusing layers... \n","YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients, 4.5 GFLOPs\n"]}],"source":["import torch\n","from models.common import DetectMultiBackend\n","from utils.torch_utils import select_device\n","\n","weights = 'yolov5n.pt'\n","# data = 'data/nuscenes.yaml'\n","data = 'data/coco128.yaml'\n","half = False  # use FP16 half-precision inference\n","dnn = False  # use OpenCV DNN for ONNX inference\n","device = select_device('cpu')\n","\n","model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n","\n","# inference\n","model.eval()\n","with torch.no_grad():\n","    pred = model(imgs)  # forward"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e4H4yzsmBgjo"},"outputs":[],"source":["from utils.general import non_max_suppression\n","\n","conf_thres = 0.25  # confidence threshold\n","iou_thres = 0.45  # NMS IOU threshold\n","max_det = 1000  # maximum detections per image\n","classes = None\n","agnostic_nms = False  # class-agnostic NMS\n","\n","pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n","\n","# [TODO] draw predictions (see detect.py:L178)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"7ukMDbxkQW5y"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}